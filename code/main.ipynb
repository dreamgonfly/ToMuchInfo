{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--save_every'], dest='save_every', nargs=None, const=None, default=1, type=<class 'int'>, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ConvolutionalBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, first_stride=1):\n",
    "        super(ConvolutionalBlock, self).__init__()\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, stride=first_stride, padding=1),\n",
    "            nn.Dropout(p=0.5)\n",
    "            nn.BatchNorm1d(num_features=out_channels), nn.ReLU(),\n",
    "            nn.Conv1d(out_channels, out_channels, kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.Dropout(p=0.5)\n",
    "            nn.BatchNorm1d(num_features=out_channels), nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequential(x)\n",
    "\n",
    "\n",
    "class KMaxPool(nn.Module):\n",
    "    def __init__(self, k='half'):\n",
    "        super(KMaxPool, self).__init__()\n",
    "\n",
    "        self.k = k\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x : batch_size, channel, time_steps\n",
    "        if self.k == 'half':\n",
    "            time_steps = x.shape(2)\n",
    "            self.k = time_steps // 2\n",
    "        kmax, kargmax = x.topk(self.k, dim=2)\n",
    "        return kmax\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, downsample=False, downsample_type='resnet', optional_shortcut=True):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.optional_shortcut = optional_shortcut\n",
    "        self.downsample = downsample\n",
    "\n",
    "        if self.downsample:\n",
    "            if downsample_type == 'resnet':\n",
    "                self.pool = None\n",
    "                first_stride = 2\n",
    "            elif downsample_type == 'kmaxpool':\n",
    "                self.pool = KMaxPool(k='half')\n",
    "                first_stride = 1\n",
    "            elif downsample_type == 'vgg':\n",
    "                self.pool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "                first_stride = 1\n",
    "            else:\n",
    "                raise NotImplementedError()\n",
    "        else:\n",
    "            first_stride = 1\n",
    "\n",
    "        self.convolutional_block = ConvolutionalBlock(in_channels, out_channels, first_stride=first_stride)\n",
    "\n",
    "        if self.optional_shortcut and self.downsample:\n",
    "            self.shortcut = nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        residual = x\n",
    "        if self.downsample and self.pool:\n",
    "            x = self.pool(x)\n",
    "        x = self.convolutional_block(x)\n",
    "\n",
    "        if self.optional_shortcut and self.downsample:\n",
    "            residual = self.shortcut(residual)\n",
    "\n",
    "        if self.optional_shortcut:\n",
    "            x = x + residual\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class VDCNN_feat(nn.Module):\n",
    "    def __init__(self, config, n_features):\n",
    "        super(VDCNN_feat, self).__init__()\n",
    "\n",
    "        vocabulary_size = config.vocabulary_size\n",
    "\n",
    "        depth = 9 # config.depth  # 29\n",
    "        embed_size = config.embedding_size # config.embed_size  # 16\n",
    "        optional_shortcut = True # config.optional_shortcut  # True\n",
    "        k = 8 # config.k  # 8\n",
    "\n",
    "        if depth == 9:\n",
    "            n_conv_layers = {'conv_block_512': 2, 'conv_block_256': 2, 'conv_block_128': 2, 'conv_block_64': 2}\n",
    "        elif depth == 17:\n",
    "            n_conv_layers = {'conv_block_512': 2, 'conv_block_256': 2, 'conv_block_128': 2, 'conv_block_64': 2}\n",
    "        elif depth == 29:\n",
    "            n_conv_layers = {'conv_block_512': 4, 'conv_block_256': 4, 'conv_block_128': 10, 'conv_block_64': 10}\n",
    "        elif depth == 49:\n",
    "            n_conv_layers = {'conv_block_512': 6, 'conv_block_256': 10, 'conv_block_128': 16, 'conv_block_64': 16}\n",
    "\n",
    "        # quantization\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocabulary_size, embedding_dim=embed_size, padding_idx=0)\n",
    "\n",
    "        conv_layers = []\n",
    "        conv_layers.append(nn.Conv1d(16, 64, kernel_size=3, padding=1))\n",
    "\n",
    "        for i in range(n_conv_layers['conv_block_64']):\n",
    "            conv_layers.append(ResidualBlock(64, 64, optional_shortcut=optional_shortcut))\n",
    "\n",
    "        for i in range(n_conv_layers['conv_block_128']):\n",
    "            if i == 0:\n",
    "                conv_layers.append(ResidualBlock(64, 128, downsample=True, optional_shortcut=optional_shortcut))\n",
    "            conv_layers.append(ResidualBlock(128, 128, optional_shortcut=optional_shortcut))\n",
    "\n",
    "        for i in range(n_conv_layers['conv_block_256']):\n",
    "            if i == 0:\n",
    "                conv_layers.append(ResidualBlock(128, 256, downsample=True, optional_shortcut=optional_shortcut))\n",
    "            conv_layers.append(ResidualBlock(256, 256, optional_shortcut=optional_shortcut))\n",
    "\n",
    "        for i in range(n_conv_layers['conv_block_512']):\n",
    "            if i == 0:\n",
    "                conv_layers.append(ResidualBlock(256, 512, downsample=True, optional_shortcut=optional_shortcut))\n",
    "            conv_layers.append(ResidualBlock(512, 512, optional_shortcut=optional_shortcut))\n",
    "\n",
    "        self.conv_layers = nn.Sequential(*conv_layers)\n",
    "        self.kmax_pooling = KMaxPool(k=k)\n",
    "\n",
    "        linear_layers = []\n",
    "\n",
    "        linear_layers.append(nn.Linear(512 * k, 2048))\n",
    "        linear_layers.append(nn.Linear(2048, 2048))\n",
    "        linear_layers.append(nn.Linear(2048, 128))\n",
    "\n",
    "        self.linear_layers = nn.Sequential(*linear_layers)\n",
    "\n",
    "        self.final_layer = nn.Linear(128 + n_features, 1)\n",
    "        self.final_bn = nn.BatchNorm1d(num_features=128 + n_features)\n",
    "\n",
    "    def forward(self, sentences, features):\n",
    "\n",
    "        x = self.embedding(sentences)\n",
    "        x = x.transpose(1, 2)  # (batch_size, sequence_length, embed_size) -> (batch_size, embed_size, sequence_length)\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.kmax_pooling(x)\n",
    "        # print(x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # print(x.shape)\n",
    "        x = self.linear_layers(x)\n",
    "        x_features = torch.cat([x, features], dim=1)\n",
    "        final_output = self.final_layer(self.final_bn(x_features))\n",
    "        return final_output.squeeze()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = args.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 04-04 00:20:27 > Arguments: Namespace(batch_size=64, embedding_size=100, epochs=10, iteration='0', learning_rate=0.01, max_vocab_size=10000, min_count=3, mode='train', output=1, pause=0, print_every=1, save_every=1, sentence_length=20, use_gpu=True)\n"
     ]
    }
   ],
   "source": [
    "logger = utils.get_logger('MovieReview')\n",
    "logger.info('Arguments: {}'.format(config))\n",
    "\n",
    "if not HAS_DATASET and not IS_ON_NSML:  # It is not running on nsml\n",
    "    DATASET_PATH = 'data/movie_review_phase1/'\n",
    "\n",
    "# DONOTCHANGE: They are reserved for nsml\n",
    "if config.pause:\n",
    "    nsml.paused(scope=locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 04-04 00:20:28 > Loading data...\n",
      "[INFO] 04-04 00:20:28 > Building preprocessor...\n",
      "[INFO] 04-04 00:20:29 > Making dataset & dataloader...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5692 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-343486eae613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     trainer = Trainer(model, train_dataloader, val_dataloader, criterion=criterion, optimizer=optimizer,\n\u001b[1;32m     36\u001b[0m                       lr_schedule=False, lr_scheduler=None, use_gpu=config.use_gpu, logger=logger)\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# 로컬 테스트 모드일때 사용합니다\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dreamgonfly/ToMuchInfo/code/trainers.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mepoch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_epoch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_epoch_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_schedule\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_epoch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dreamgonfly/ToMuchInfo/code/trainers.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mbatch_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dreamgonfly/ToMuchInfo/code/trainers.py\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(self, outputs, labels)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mmaximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0mcorrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margmax\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m  \u001b[0;31m# ByteTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mn_corrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# FloatTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "if config.mode == 'train':\n",
    "    # 데이터를 로드합니다.\n",
    "    logger.info(\"Loading data...\")\n",
    "    train_data, val_data = load_data(DATASET_PATH, val_size=0.3)\n",
    "\n",
    "    logger.info(\"Building preprocessor...\")\n",
    "    tokenizer = DummyTokenizer(config)\n",
    "    feature_extractor1 = LengthFeatureExtractor(config)\n",
    "    feature_extractors = [feature_extractor1]\n",
    "    dictionary = RandomWordDictionary(tokenizer, config)\n",
    "    dictionary.build_dictionary(train_data)\n",
    "\n",
    "    preprocessor = Preprocessor(tokenizer, feature_extractors, dictionary)\n",
    "\n",
    "    logger.info(\"Making dataset & dataloader...\")\n",
    "    train_dataset = MovieReviewDataset(train_data, preprocessor, sort=False, min_length=config.sentence_length, max_length=config.sentence_length)\n",
    "    val_dataset = MovieReviewDataset(val_data, preprocessor, sort=False, min_length=config.sentence_length, max_length=config.sentence_length)\n",
    "\n",
    "    train_dataloader = DataLoader(dataset=train_dataset, batch_size=config.batch_size, shuffle=True, collate_fn=collate_fn,\n",
    "                              num_workers=2)\n",
    "    val_dataloader = DataLoader(dataset=val_dataset, batch_size=config.batch_size, shuffle=True,\n",
    "                                  collate_fn=collate_fn, num_workers=2)\n",
    "\n",
    "    model = WordCNN(dictionary, config)\n",
    "    if config.use_gpu:\n",
    "        model = model.cuda()\n",
    "\n",
    "    # DONOTCHANGE: Reserved for nsml use\n",
    "    bind_model(model, config)\n",
    "\n",
    "    criterion = nn.MSELoss(size_average=False)\n",
    "    trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = optim.Adam(params=trainable_params, lr=0.01)\n",
    "\n",
    "    trainer = Trainer(model, train_dataloader, val_dataloader, criterion=criterion, optimizer=optimizer,\n",
    "                      lr_schedule=False, lr_scheduler=None, use_gpu=config.use_gpu, logger=logger)\n",
    "    trainer.run(epochs=config.epochs)\n",
    "\n",
    "# 로컬 테스트 모드일때 사용합니다\n",
    "# 결과가 아래와 같이 나온다면, nsml submit을 통해서 제출할 수 있습니다.\n",
    "# [(0.0, 9.045), (0.0, 5.91), ... ]\n",
    "elif config.mode == 'test_local':\n",
    "    with open(os.path.join(DATASET_PATH, 'train/train_data'), 'rt', encoding='utf-8') as f:\n",
    "        reviews = f.readlines()\n",
    "    res = nsml.infer(reviews)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/dreamgonfly/ToMuchInfo/code/trainers.py\u001b[0m(128)\u001b[0;36maccuracy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    126 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    127 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 128 \u001b[0;31m        \u001b[0mmaximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    129 \u001b[0;31m        \u001b[0mcorrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margmax\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m  \u001b[0;31m# ByteTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    130 \u001b[0;31m        \u001b[0mn_corrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# FloatTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> outputs\n",
      "Variable containing:\n",
      " 0.1273\n",
      "-0.5819\n",
      "-0.6532\n",
      "-0.1320\n",
      "-0.5961\n",
      "-0.7171\n",
      "-0.2539\n",
      "-0.3998\n",
      " 0.2566\n",
      "-0.1505\n",
      "-0.1322\n",
      "-0.9903\n",
      "-0.0822\n",
      "-0.6006\n",
      "-0.4758\n",
      "-0.1860\n",
      "-0.5150\n",
      " 0.3142\n",
      "-0.6494\n",
      "-0.2082\n",
      "-0.2085\n",
      " 0.5739\n",
      "-0.1720\n",
      "-0.2616\n",
      " 0.0220\n",
      " 0.0347\n",
      "-0.7987\n",
      "-0.2172\n",
      "-0.2854\n",
      " 0.2944\n",
      "-0.2350\n",
      "-0.1923\n",
      "-0.2108\n",
      "-0.2737\n",
      "-0.1808\n",
      "-0.2512\n",
      "-1.1263\n",
      "-0.0365\n",
      "-0.3680\n",
      "-0.9781\n",
      "-0.0289\n",
      "-0.0150\n",
      "-0.6240\n",
      "-0.4060\n",
      "-0.3134\n",
      "-0.1466\n",
      "-0.0693\n",
      "-0.1734\n",
      "-0.3881\n",
      "-0.3648\n",
      "-0.6657\n",
      " 0.3251\n",
      "-0.2684\n",
      "-0.0434\n",
      "-0.0293\n",
      "-0.4846\n",
      " 0.4403\n",
      "-0.5882\n",
      " 0.2339\n",
      " 0.3458\n",
      "-0.2400\n",
      "-0.0320\n",
      "-0.3078\n",
      "-0.3777\n",
      "[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
